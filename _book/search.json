[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Quarto CRC Book",
    "section": "",
    "text": "Preface\nThis is a Quarto book."
  },
  {
    "objectID": "index.html#software-conventions",
    "href": "index.html#software-conventions",
    "title": "Quarto CRC Book",
    "section": "Software conventions",
    "text": "Software conventions\n\n1 + 1\n\n2\n\n\nTo learn more about Quarto books visit https://quarto.org/docs/books."
  },
  {
    "objectID": "index.html#acknowledgments",
    "href": "index.html#acknowledgments",
    "title": "Quarto CRC Book",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nBlah, blah, blah…"
  },
  {
    "objectID": "main.html#bussiness-understanding",
    "href": "main.html#bussiness-understanding",
    "title": "1  TUGAS KLASIFIKASI DATA PROYEK SAINS DATA - B",
    "section": "1.1 BUSSINESS UNDERSTANDING",
    "text": "1.1 BUSSINESS UNDERSTANDING\n\n1.1.1 Identifikasi kasus :\nGlioma merupakan penyakit tumor yang berasal dari pertumbuhan abnormal pada sel-sel glial, yaitu sel-sel yang mendukung dan melindungi sel-sel saraf di dalam otak dan sumsum tulang belakang,dapat dibagi menjadi 2 kategori utama yaitu Lower-Grade Gliomas (LGG) adalah jenis glioma yang memiliki pertumbuhan lebih lambat dan umumnya dianggap sebagai tumor yang kurang agresif dibandingkan dengan Glioblastoma Multiforme (GBM) merupakan glioma yang sangat agresif dan tumbuh dengan cepat.\n\n\n1.1.2 Tujuan Proyek :\nTujuan yaitu melakukan klasifikasi pasien menjadi dua kelompok berdasarkan ciri klinis dan molekuler/mutasi tertentu, yaitu apakah pasien tersebut memiliki Lower-Grade Glioma (LGG) atau Glioblastoma Multiforme (GBM). Ini merupakan tugas klasifikasi ingin mengidentifikasi subset gen mutasi dan gambaran klinis yang optimal untuk membantu memprediksi apakah seorang pasien memiliki LGG atau GBM"
  },
  {
    "objectID": "main.html#data-understanding",
    "href": "main.html#data-understanding",
    "title": "1  TUGAS KLASIFIKASI DATA PROYEK SAINS DATA - B",
    "section": "1.2 DATA UNDERSTANDING",
    "text": "1.2 DATA UNDERSTANDING\nTahap Data Understanding merupakan tahap dimana kita perlu memahami data yang akan diolah. Adapun hal - hal yang perlu dilakukan nantinya untuk memahami dataset ini, yakni 1. Tentang data, mencakup : * Pengumpulan dataset * Pengenalan singkat mengenai data yang akan diolah 2. Mendeskripsikan data, mencakup : * analisa tipe data * deskripsi fitur 3. Eksplorasi data, mencakup : * Visualisasi data * Skoring fitur 4. Identifikasi kualitas data : * Identifikasi missing valye setiap fitur atau kolom * Identifikasi data duplikat * Identifikasi outlier (data aneh) * Identifikasi jumlah data (proporsi data perkelas -untuk mengetahui balancing dataset atau keseimbangan data per kelas)\n\n1.2.1 About Data\n\n1.2.1.1 Pengumpulan Dataset\nPada tanggal 13 Desember 2022, data fitur klinis dan mutasi glioma dievaluasi, yang diperoleh melalui platform Kaggle, menjadi sumber informasi yang relevan\n\nimport pandas as pd\n\ndata = pd.read_csv('dataset.csv')\ndata.head(5)\n\n\n\n\n\n\n\n\nGrade\nGender\nAge_at_diagnosis\nRace\nIDH1\nTP53\nATRX\nPTEN\nEGFR\nCIC\n...\nFUBP1\nRB1\nNOTCH1\nBCOR\nCSMD3\nSMARCA4\nGRIN2A\nIDH2\nFAT4\nPDGFRA\n\n\n\n\n0\n0\n0\n51.30\n0\n1\n0\n0\n0\n0\n0\n...\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n38.72\n0\n1\n0\n0\n0\n0\n1\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n2\n0\n0\n35.17\n0\n1\n1\n1\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3\n0\n1\n32.78\n0\n1\n1\n1\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n\n\n4\n0\n0\n31.51\n0\n1\n1\n1\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n5 rows × 24 columns\n\n\n\n\n\n1.2.1.2 Seputar dataset\n\nprint(\"Banyaknya data : \", data.shape[0])\n\nBanyaknya data :  839\n\n\n\n\n1.2.1.3 Mendeskripsikan Fitur\n\nprint(\"Banyaknya kolom : \", data.shape[1])\n\nBanyaknya kolom :  24\n\n\nPenjelasan fitur\n\nGrade (Tingkat Keparahan): Menunjukkan sejauh mana tumor otak (glioma) tumbuh dan seberapa ganas tumor tersebut, berdasarkan pada sistem penilaian tertentu. Skala gradasi berkisar dari I (tumor jinak) hingga IV (tumor ganas).\nGender (Jenis Kelamin): Informasi tentang jenis kelamin pasien yang menderita glioma. Berguna untuk analisis epidemiologi dan pemahaman apakah terdapat perbedaan insidensi glioma antara laki-laki dan perempuan.\n(Usia pada Saat Diagnosa): Usia pasien saat glioma pertama kali didiagnosis. Penting karena dapat memengaruhi pilihan pengobatan dan prognosis glioma, mengingat glioma dapat muncul pada berbagai kelompok usia.\nRace (Ras): Informasi tentang ras pasien, membantu analisis untuk memahami apakah ada perbedaan kejadian glioma di antara kelompok etnis.\nIDH1 (Isocitrate Dehydrogenase 1): Menunjukkan status mutasi gen IDH1, yang sering terlibat dalam perkembangan glioma dan dapat memengaruhi karakteristik dan prognosis glioma.\nTP53 (Tumor Protein p53): Informasi tentang status gen TP53 dalam glioma, yang berperan sebagai gen penekan tumor dan mutasinya dapat memengaruhi pertumbuhan dan perkembangan glioma.\nATRX (Alpha Thalassemia/Mental Retardation Syndrome X-Linked): Menyajikan status gen ATRX, terkait dengan glioma, dan mutasinya dapat memengaruhi sifat molekuler glioma.\nPTEN (Phosphatase and Tensin Homolog): Menunjukkan status gen PTEN yang berperan dalam perkembangan glioma dan mutasinya dapat memengaruhi pertumbuhan tumor otak.\nEGFR (Epidermal Growth Factor Receptor): Informasi tentang gen EGFR dalam konteks glioma. Amplifikasi atau mutasi gen EGFR dapat ditemukan dalam beberapa jenis glioma dan memengaruhi respons terhadap pengobatan.\nCIC (Capicua Transcriptional Repressor): Gen yang terlibat dalam regulasi pertumbuhan sel dan perkembangan glioma.\nMUC16 (Mucin 16): Merujuk kepada gen atau molekul tertentu terkait dengan glioma, memerlukan informasi lebih lanjut untuk penjelasan yang lebih spesifik.\nPIK3CA (Phosphatidylinositol-4,5-Bisphosphate 3-Kinase Catalytic Subunit Alpha): Menunjukkan informasi tentang gen PIK3CA yang terkait dengan glioma.\nNF1 (Neurofibromatosis Type 1): Informasi tentang gen NF1 dalam konteks glioma.\nPIK3R1 (Phosphoinositide-3-Kinase Regulatory Subunit 1): Menunjukkan informasi tentang gen PIK3R1.\nFUBP1 (Far Upstream Element Binding Protein 1): Gen yang terkait dengan regulasi transkripsi gen dalam konteks glioma.\nRB1 (Retinoblastoma 1): Menyajikan informasi tentang gen RB1, gen penekan tumor yang memengaruhi siklus sel dalam konteks glioma.\nNOTCH1 (Notch Receptor 1): Informasi tentang gen NOTCH1 dalam glioma, yang terlibat dalam regulasi pertumbuhan sel dan pembentukan jaringan.\nBCOR (BCL6 Corepressor): Merujuk kepada gen BCOR terkait dengan beberapa jenis kanker.\nCSMD3 (CUB and Sushi Multiple Domains 3): Merujuk kepada gen atau molekul terkait dengan glioma.\nSMARCA4 (SWI/SNF Related, Matrix Associated, Actin Dependent Regulator Of Chromatin, Subfamily A, Member 4): Menunjukkan informasi tentang gen SMARCA4 dalam keluarga gen regulasi kromatin.\nGRIN2A (Glutamate Ionotropic Receptor NMDA Type Subunit 2A): Merujuk kepada gen GRIN2A terkait dengan glioma.\nIDH2 (Isocitrate Dehydrogenase 2): Menunjukkan informasi tentang gen IDH2 yang terlibat dalam glioma dan sering dihubungkan dengan IDH1.\nFAT4 (FAT Atypical Cadherin 4): Merujuk kepada gen FAT4 terkait dengan beberapa jenis kanker.\nPDGFRA (Platelet-Derived Growth Factor Receptor Alpha): Menyajikan informasi tentang gen PDGFRA dalam konteks glioma, terlibat dalam jalur pertumbuhan sel dan pembentukan pembuluh darah.\n\n\n\n\n1.2.2 Mendeskripsikan Data\n\ndata.columns\n\nIndex(['Grade', 'Gender', 'Age_at_diagnosis', 'Race', 'IDH1', 'TP53', 'ATRX',\n       'PTEN', 'EGFR', 'CIC', 'MUC16', 'PIK3CA', 'NF1', 'PIK3R1', 'FUBP1',\n       'RB1', 'NOTCH1', 'BCOR', 'CSMD3', 'SMARCA4', 'GRIN2A', 'IDH2', 'FAT4',\n       'PDGFRA'],\n      dtype='object')\n\n\n\n1.2.2.1 Analisa Tipe data\nDalam analisa data, terdapat beberapa tipe data yang sering ditemukan. Pemahaman tipe data ini penting karena berbagai jenis analisis statistik dan pemrosesan data dapat memerlukan pendekatan yang berbeda tergantung pada jenis data yang digunakan.\nBerikut adalah Macam - Macam Data yang ada pada data ini.\n\nTipe nominal\n\nmemiliki value 1 yang melambangkan ya dan 0 yang melambangkan tidak. &gt; Pada data ini mencakup fitur : ‘Grade’, ‘Gender’, ‘Race’, ‘IDH1’, ‘TP53’, ‘ATRX’, ‘PTEN’, ‘EGFR’, ‘CIC’, ‘MUC16’, ‘PIK3CA’, ‘NF1’, ‘PIK3R1’, ‘FUBP1’, ‘RB1’, ‘NOTCH1’, ‘BCOR’, ‘CSMD3’, ‘SMARCA4’, ‘GRIN2A’, ‘IDH2’, ‘FAT4’, ’PDGFRA\nmencakup tipe data numeric. &gt; yakni Age_at_diagnosis\n\n\n\n\n\n1.2.3 Deskripsi Fitur\n\nGrade (Kelas Tingkat Keparahan Tumor) Deskripsi: Menunjukkan tingkat keparahan tumor. Contoh Nilai: &gt; 1 : Tumor dengan pertumbuhan lambat (Tingkat I)\n\n2 : Tumor dengan pertumbuhan yang lebih cepat (Tingkat II)\n\n\n3 : Tumor yang lebih agresif (Tingkat III)\n\n\n4 : Tumor ganas dengan pertumbuhan paling cepat (Tingkat IV)\n\nGender (Jenis Kelamin) Deskripsi: Menunjukkan jenis kelamin pasien. Contoh Nilai: &gt; 0 : perempuan\n\n1 : laki - laki\n\nAge_at_diagnosis (Usia pada Saat Diagnosis Tumor) Deskripsi: Menunjukkan usia pasien pada saat diagnosis tumor. Contoh Nilai: &gt; 25: Pasien didiagnosis pada usia 25 tahun\n\n60: Pasien didiagnosis pada usia 60 tahun\n\nRace (Ras) Deskripsi: Menunjukkan ras pasien. Contoh Nilai: &gt; 0 : Tidak memiliki ras\n\n1 : memiliki ras\n\nIDH1 Deskripsi: Menunjukkan status mutasi pada gen IDH1, yang dapat menjadi petunjuk untuk jenis tumor tertentu, seperti glioma. Contoh Nilai: &gt; 0 : Tidak ada mutasi\n\n1: Ada mutasi\n\nTP53 Deskripsi: Menunjukkan status mutasi pada gen TP53, yang terlibat dalam pengawasan pertumbuhan sel dan dapat terlibat dalam perkembangan tumor. Contoh Nilai: &gt; 0 : Tidak ada mutasi\n\n1: Ada mutasi\n\nATRX Deskripsi: Menunjukkan status mutasi pada gen ATRX, yang terlibat dalam regulasi panjang telomer dan stabilitas kromosom. Contoh Nilai: &gt; 0 : Tidak ada mutasi\n\n1: Ada mutasi\n\nPTEN Deskripsi: Menunjukkan status mutasi pada gen PTEN, yang berperan dalam pengawasan pertumbuhan sel dan dapat terlibat dalam perkembangan kanker. Contoh Nilai: &gt; 0 : Tidak ada mutasi\n\n1: Ada mutasi\n\nEGFR Deskripsi: Menunjukkan status mutasi pada gen EGFR, yang dapat terlibat dalam pertumbuhan sel dan sering diidentifikasi pada beberapa jenis kanker. Contoh Nilai: &gt; 0 : Tidak ada mutasi\n\n1: Ada mutasi\n\nCIC Deskripsi: Menunjukkan status mutasi pada gen CIC, yang terlibat dalam regulasi siklus sel dan dapat terlibat dalam perkembangan tumor. Contoh Nilai: &gt; 0 : Tidak ada mutasi\n\n1: Ada mutasi\n\nMUC16 Deskripsi: Menunjukkan status mutasi pada gen MUC16, yang dapat terlibat dalam perkembangan beberapa jenis kanker. Contoh Nilai: &gt; 0 : Tidak ada mutasi\n\n1: Ada mutasi\n\nPIK3CA Deskripsi: Menunjukkan status mutasi pada gen PIK3CA, yang terlibat dalam jalur sinyal pertumbuhan sel. Contoh Nilai: &gt; 0 : Tidak ada mutasi\n\n1: Ada mutasi\n\nNF1 Deskripsi: Menunjukkan status mutasi pada gen NF1, yang terlibat dalam regulasi pertumbuhan sel dan dapat terlibat dalam perkembangan tumor. Contoh Nilai: &gt; 0 : Tidak ada mutasi\n\n1: Ada mutasii\n\nPIK3R1 Deskripsi: Menunjukkan status mutasi pada gen PIK3R1, yang terlibat dalam regulasi jalur PI3K-Akt. Contoh Nilai: &gt; 0 : Tidak ada mutasi\n\n1: Ada mutasi\n\nFUBP1 Deskripsi: Menunjukkan status mutasi pada gen FUBP1, yang dapat terlibat dalam regulasi ekspresi gen. Contoh Nilai: &gt; 0 : Tidak ada mutasi\n\n1: Ada mutasi\n\nRB1 Deskripsi: Menunjukkan status mutasi pada gen RB1, yang terlibat dalam regulasi siklus sel. Contoh Nilai: &gt; 0 : Tidak ada mutasi\n\n1: Ada mutasi\n\nNOTCH1 Deskripsi: Menunjukkan status mutasi pada gen NOTCH1, yang dapat terlibat dalam regulasi diferensiasi sel dan pertumbuhan. Contoh Nilai: &gt; 0 : Tidak ada mutasi\n\n1: Ada mutasi\n\nBCOR Deskripsi: Menunjukkan status mutasi pada gen BCOR, yang terlibat dalam regulasi ekspresi gen dan diferensiasi sel. Contoh Nilai: &gt; 0 : Tidak ada mutasi\n\n1: Ada mutasi\n\nCSMD3 Deskripsi: Menunjukkan status mutasi pada gen CSMD3, yang dapat terlibat dalam regulasi pertumbuhan sel. Contoh Nilai: &gt; 0 : Tidak ada mutasi\n\n1: Ada mutasi\n\nSMARCA4 Deskripsi: Menunjukkan status mutasi pada gen SMARCA4, yang terlibat dalam regulasi struktur kromosom dan pertumbuhan sel. Contoh Nilai: &gt; 0 : Tidak ada mutasi\n\n1: Ada mutasi\n\nGRIN2A Deskripsi: Menunjukkan status mutasi pada gen GRIN2A, yang terlibat dalam transmisi sinyal sel saraf. Contoh Nilai: &gt; 0 : Tidak ada mutasi\n\n1: Ada mutasi\n\nIDH2 Deskripsi: Menunjukkan status mutasi pada gen IDH2, yang dapat terkait dengan jenis tumor tertentu. Contoh Nilai: &gt; 0 : Tidak ada mutasi\n\n1: Ada mutasi\n\nFAT4 Deskripsi: Menunjukkan status mutasi pada gen FAT4, yang terlibat dalam regulasi pertumbuhan sel. Contoh Nilai: &gt; 0 : Tidak ada mutasi\n\n1: Ada mutasi\n\nPDGFRA Deskripsi: Menunjukkan status mutasi pada gen PDGFRA, yang terlibat dalam pertumbuhan dan pemeliharaan sel. Contoh Nilai: &gt; 0 : Tidak ada mutasi\n\n1: Ada mutasi\n\n\n\n\n1.2.4 Eksplorasi Data\n\n1.2.4.1 Visualisasi Data\nVisualisasi data dilakukan untuk memudahkan kita memahami data. Melalui visualisasi data pula kita akan memperoleh informasi sebaran nilai dari dataset ini\n\nimport matplotlib.pyplot as plt\n\ndata.hist(figsize=(14,14))\nplt.show\n\n&lt;function matplotlib.pyplot.show(close=None, block=None)&gt;\n\n\n\n\n\n\n\n1.2.4.2 Skoring Fitur\nDengan melakukan skoring fitur, kita akan mengetahui yang mana fitur yang penting dan yang tidak. Hal ini dikarenakan tidak semua fitur dapat dijadikan ciri untuk melakukan klasifikasi. Dengan menentukan beberapa ciri terbaik akan menghasilkan akurasi yang sama atau lebih baik dibandingkan dengan menggunakan semua ciri serta menghemat waktu komputasi.\n\nfrom sklearn.feature_selection import SelectKBest, mutual_info_classif\n\n# memisahkan kolom fitur dan target\nfitur = data.drop(columns=['Grade'], axis =1)\ntarget = data['Grade']\n\n# Buat objek SelectKBest dengan mutual_info_classif sebagai fungsi skor\nk_best = SelectKBest(score_func=mutual_info_classif, k='all')  # 'all' berarti akan mempertahankan semua fitur\n\n# Hitung skor fitur\nk_best.fit(fitur, target)\nscores = k_best.scores_\n\n# Dapatkan nama fitur dari kolom data Anda\nfitur_names = fitur.columns\n\n# Tampilkan skor fitur berserta namanya\nfor i, (score, fitur_name) in enumerate(zip(scores, fitur_names)):\n    print(f\"Fitur {i}: {fitur_name}, Skor: {score}\")\n\nFitur 0: Gender, Skor: 0.0\nFitur 1: Age_at_diagnosis, Skor: 0.1836302604370481\nFitur 2: Race, Skor: 0.001083226817359284\nFitur 3: IDH1, Skor: 0.29916352355341314\nFitur 4: TP53, Skor: 0.004332139019691539\nFitur 5: ATRX, Skor: 0.028339027312104026\nFitur 6: PTEN, Skor: 0.07035477153576664\nFitur 7: EGFR, Skor: 0.019006818303878292\nFitur 8: CIC, Skor: 0.05872220363351821\nFitur 9: MUC16, Skor: 0.049386808646663116\nFitur 10: PIK3CA, Skor: 0.0\nFitur 11: NF1, Skor: 0.0\nFitur 12: PIK3R1, Skor: 0.006321600145554607\nFitur 13: FUBP1, Skor: 0.02634246570829135\nFitur 14: RB1, Skor: 0.01660825390759091\nFitur 15: NOTCH1, Skor: 0.0\nFitur 16: BCOR, Skor: 0.0\nFitur 17: CSMD3, Skor: 0.0\nFitur 18: SMARCA4, Skor: 0.005637498408886277\nFitur 19: GRIN2A, Skor: 0.031420500403958496\nFitur 20: IDH2, Skor: 0.0058230458756221015\nFitur 21: FAT4, Skor: 0.0\nFitur 22: PDGFRA, Skor: 0.0\n\n\n\nimport matplotlib.pyplot as plt\n\n# Tampilkan skor fitur dalam grafik\nplt.figure(figsize=(18, 6))\nplt.bar(fitur_names, scores)\nplt.xlabel(\"Nama Fitur\")\nplt.ylabel(\"Skor Fitur\")\nplt.title(\"Skor Fitur SelectKBest\")\nplt.xticks(rotation=90)\nplt.show()\n\n\n\n\n\n\n\n1.2.5 Mengidentifikasi Kualitas Data\n\n1.2.5.1 Identifikasi missing value\nIdentifikasi nilai yang hilang (missing value) adalah proses untuk menemukan dan mengenali keberadaan nilai yang tidak ada atau kosong dalam suatu dataset. Langkah-langkah umum untuk mengidentifikasi missing value melibatkan: 1. Pemeriksaan Visual: Tinjau dataset secara visual, terutama jika ukurannya tidak terlalu besar. Identifikasi apakah ada nilai yang kosong atau tidak biasa. 2. Statistik Deskriptif: Gunakan metode statistik deskriptif seperti fungsi mean, median, dan std deviation untuk melihat apakah terdapat nilai yang tidak valid atau tidak sesuai dengan harapan. 3. Pemetaan Nilai yang Hilang: Representasikan missing value dengan visualisasi, seperti heatmap, untuk memahami pola distribusi nilai yang hilang dalam dataset. 4. Fungsi atau Metode Khusus: Gunakan fungsi atau metode khusus dalam bahasa pemrograman atau perangkat lunak analisis data untuk mengidentifikasi secara otomatis nilai yang hilang, seperti fungsi isna() atau isnull() dalam Python. 5. Analisis Korelasi: Evaluasi korelasi antara variabel yang memiliki missing value dengan variabel lain dalam dataset untuk memahami apakah ada pola atau hubungan yang dapat membantu dalam pengelolaan missing value.\nPenanganan Missing Value : Jika atribut tersebut memiliki banyak missing value, maka atribut tersebut perlu dihapus dari dataset. Namun jika hanya terdapat beberapa data yang missing value bisa dilakukan drop dari baris yang memiliki missing value atau mengisinya dengan rata - rata nilai pada atribut yang bersangkutan.\n\n# mengecek apakah ada nilai yang hilang dalam setiap kolom\nmissing_values = data.isna().any()\n\n# menampilkan hasil\nprint(\"Apakah ada nilai yang hilang dalam setiap kolom:\")\nprint(missing_values)\n\nApakah ada nilai yang hilang dalam setiap kolom:\nGrade               False\nGender              False\nAge_at_diagnosis    False\nRace                False\nIDH1                False\nTP53                False\nATRX                False\nPTEN                False\nEGFR                False\nCIC                 False\nMUC16               False\nPIK3CA              False\nNF1                 False\nPIK3R1              False\nFUBP1               False\nRB1                 False\nNOTCH1              False\nBCOR                False\nCSMD3               False\nSMARCA4             False\nGRIN2A              False\nIDH2                False\nFAT4                False\nPDGFRA              False\ndtype: bool\n\n\nNoted : tidak ada missing value pada data\n\n\n1.2.5.2 Identifikasi Duplikat Data\nDuplikat data merupakan suatu kondisi dimana suatu baris memiliki nilai yang sama persis di semua kolom pada baris lainnya. Adanya data yang redundan (berulang) dapat mengganggu hasil analisis dan menghasilkan akurasi yang tidak akurat. Untuk mengecek adanya duplikat data, maka digunakan fungsi dupicated()\n\njumlah_duplikat = data.duplicated().sum()\n\n# Menampilkan jumlah data yang duplikat\nprint(\"Jumlah data yang duplikat:\", jumlah_duplikat)\n\nJumlah data yang duplikat: 1\n\n\nNoted : terdapat 1 data duplikat\n\n\n1.2.5.3 Identifikasi Outlier\nOutlier, pada dasarnya, adalah suatu nilai yang secara signifikan menonjol dan berbeda jauh dari nilai-nilai lain dalam suatu set data. Kadang-kadang disebut sebagai nilai ekstrem, outlier tidak hanya mencolok tetapi juga memiliki sifat yang tidak representatif terhadap fenomena sekitarnya. Deteksi outlier menjadi penting dalam analisis data, karena keberadaannya dapat mengganggu hasil analisis keseluruhan dan memengaruhi kesimpulan yang dapat diambil dari dataset tersebut\n\nfrom sklearn.neighbors import LocalOutlierFactor\n\n# Menggunakan Local Outlier Factor\nlof = LocalOutlierFactor(n_neighbors=5)\noutlier_scores = lof.fit_predict(data)\n\noutliers = data[outlier_scores == -1]\nprint(\"Banyaknya outlier : \", outliers.shape[0])\n\ndata_bersih = data[outlier_scores != -1]\nprint(\"Sisa data : \", data_bersih.shape[0])\n\nBanyaknya outlier :  29\nSisa data :  810\n\n\n\n\n1.2.5.4 Identifikasi Jumlah Data\nDengan mengetahui proporsi data untuk masing - masing label, kita bisa mengetahui seberapa berbeda jumlah data di tiap - tiap label. Jika jumlah data antar label memiliki perbedaan yang sangat jauh maka akan mempengaruhi akurasi serta hasil klasifikasi sehingga nantinya perlu dilakukan penyeimbangan jumlah data di tiap labelnya.\n\n# Menghitung jumlah target pada data tanpa outlier\ntarget_no_outliers = data['Grade'].value_counts()\n\nprint(\"Jumlah data pada tiap target :\")\nprint(target_no_outliers)\n\nJumlah data pada tiap target :\nGrade\n0    487\n1    352\nName: count, dtype: int64\n\n\n\n\n\n1.2.6 Hasil Analisa Pada Data Understanding :\n\nData tidak memiliki missing values\nData memiliki 1 data redundan\nData memiliki 29 outlier"
  },
  {
    "objectID": "main.html#data-preprocessing",
    "href": "main.html#data-preprocessing",
    "title": "1  TUGAS KLASIFIKASI DATA PROYEK SAINS DATA - B",
    "section": "1.3 DATA PREPROCESSING",
    "text": "1.3 DATA PREPROCESSING\nSetelah memahami data, akan dilakukan tahap preprocessing untuk menangani masalah pada data yang sudah didefinisikan pada data understanding, yakni. 1. Menghapus Data Duplikat 2. Menghapus Outlier 3. Menyeimbangkan proporsi data tiap target\nSetelah data siap, akan dilakukan skoring fitur kembali.\n\nimport pandas as pd\n\ndata = pd.read_csv('dataset.csv')\ndata.head(5)\n\n\n\n\n\n\n\n\nGrade\nGender\nAge_at_diagnosis\nRace\nIDH1\nTP53\nATRX\nPTEN\nEGFR\nCIC\n...\nFUBP1\nRB1\nNOTCH1\nBCOR\nCSMD3\nSMARCA4\nGRIN2A\nIDH2\nFAT4\nPDGFRA\n\n\n\n\n0\n0\n0\n51.30\n0\n1\n0\n0\n0\n0\n0\n...\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n38.72\n0\n1\n0\n0\n0\n0\n1\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n2\n0\n0\n35.17\n0\n1\n1\n1\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3\n0\n1\n32.78\n0\n1\n1\n1\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n\n\n4\n0\n0\n31.51\n0\n1\n1\n1\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n5 rows × 24 columns\n\n\n\n\n# Rincian dataset (banyak data dan kolom)\n\nprint(\"Banyaknya data : \", data.shape[0])\nprint(\"Banyaknya kolom : \", data.shape[1])\n\nBanyaknya data :  839\nBanyaknya kolom :  24\n\n\n\n1.3.1 Menghapus Data Duplikat\nDuplikat data merupakan suatu kondisi dimana suatu baris memiliki nilai yang sama persis di semua kolom pada baris lainnya. Adanya data yang redundan (berulang) dapat mengganggu hasil analisis dan menghasilkan akurasi yang tidak akurat.\n\n# Menghapus data yang duplikat\ndata_bersih = data.drop_duplicates()\n\nprint(\"Banyaknya sisa data : \", data_bersih.shape[0])\n\nBanyaknya sisa data :  838\n\n\n\nfrom sklearn.neighbors import LocalOutlierFactor\n\n# Menggunakan Local Outlier Factor\nlof = LocalOutlierFactor(n_neighbors=5)\noutlier_scores = lof.fit_predict(data_bersih)\n\ndata_oke = data_bersih[outlier_scores != -1]\nprint(\"Sisa data : \", data_oke.shape[0])\n\nSisa data :  810\n\n\n\n\n1.3.2 Menyeimbangkan Data Tiap Target\nDengan mengetahui proporsi data untuk masing - masing label, kita bisa mengetahui seberapa berbeda jumlah data di tiap - tiap label. Jika jumlah data antar label memiliki perbedaan yang sangat jauh maka akan mempengaruhi akurasi serta hasil klasifikasi sehingga nantinya perlu dilakukan penyeimbangan jumlah data di tiap labelnya.\n\n1.3.2.1 Proporsi Jumlah Data Di Tiap Label\n\nfitur = data_oke.drop(columns=['Grade'])\ntarget = data_oke['Grade']\n\ntarget.value_counts()\n\nGrade\n0    468\n1    342\nName: count, dtype: int64\n\n\n\n1.3.2.1.1 Visualisasi banyaknya data di tiap label\n\nimport matplotlib.pyplot as plt\n\nvalue_counts = target.value_counts()\n\nplt.pie(value_counts, labels=value_counts.index, autopct='%.2f')\nplt.title('Distribusi Kelas Target')\nplt.axis('equal')\nplt.show()\n\n\n\n\n\n\n\n1.3.2.2 Penyeimbangan jumlah atau proporsi data\nPerbandingan proporsi data tiap target sangat jauh sehingga untuk menghemat waktu komputasi output antar target akan diseimbangkan menggunakan metode UnderSampling. Undersampling adalah teknik untuk mengurangi jumlah data pada kelas mayoritas sehingga jumlahnya setara dengan kelas minoritas.\n\nfrom imblearn.under_sampling import RandomUnderSampler\n\nsmote = RandomUnderSampler()\nfitur_seimbang, target_seimbang = smote.fit_resample(fitur, target)\n\nprint(\"Jumlah sampel setelah diseimbangkan : \")\nprint(target_seimbang.value_counts())\n\nJumlah sampel setelah diseimbangkan : \nGrade\n0    342\n1    342\nName: count, dtype: int64\n\n\n\n1.3.2.2.1 Visualisasi banyaknya data di tiap label\n\nimport matplotlib.pyplot as plt\n\nfig, axs = plt.subplots(1, 2, figsize=(10, 5))\n\n# Plot distribusi kelas target sebelum penyeimbangan\ntarget_tidak_seimbang = target.value_counts()\naxs[0].pie(target_tidak_seimbang, labels=target_tidak_seimbang.index, autopct='%.2f')\naxs[0].set_title('Distribusi Kelas Target Sebelum Diseimbangkan')\naxs[0].axis('equal')\n\n# Plot distribusi kelas target setelah penyeimbangan\ntarget_sudah_seimbang = target_seimbang.value_counts()\naxs[1].pie(target_sudah_seimbang, labels=target_sudah_seimbang.index, autopct='%.2f')\naxs[1].set_title('Distribusi Kelas Target Yang Telah Diseimbangkan')\naxs[1].axis('equal')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n1.3.3 Hasil Preprocessing Data\n\nimport pandas as pd\n\n# Membuat DataFrame dari fitur dan target yang telah seimbang\ndata_seimbang = pd.concat([fitur_seimbang, target_seimbang], axis=1)\n\n# Menyimpan DataFrame ke dalam file CSV\ndata_seimbang.to_csv('data_seimbang1.csv', index=False)\n\n\n\n1.3.4 Feature Selection\nDengan melakukan skoring fitur, kita akan mengetahui yang mana fitur yang penting dan yang tidak. Hal ini dikarenakan tidak semua fitur dapat dijadikan ciri untuk melakukan klasifikasi. Dengan menentukan beberapa ciri terbaik akan menghasilkan akurasi yang sama atau lebih baik dibandingkan dengan menggunakan semua ciri serta menghemat waktu komputasi.\nSkor informasi menggunakan mutual_info_classif berguna untuk mengevaluasi seberapa informatif suatu fitur terhadap variabel target. Skoring fitur menggunakan mutual_info_classif dapat mengukur seberapa banyak informasi dari variabel independen (fitur) yang terdapat pada variabel dependen (target) dalam dataset. Secara spesifik, skor ini menunjukkan seberapa banyak informasi dari suatu fitur yang dapat membantu dalam memprediksi target. Semakin tinggi skornya, semakin informatif fitur tersebut terhadap variabel target.\n\nfrom sklearn.feature_selection import SelectKBest, mutual_info_classif\n\n# Buat objek SelectKBest dengan mutual_info_classif sebagai fungsi skor\nk_best = SelectKBest(score_func=mutual_info_classif, k='all')  # 'all' berarti akan mempertahankan semua fitur\n\n# Hitung skor fitur\nk_best.fit(fitur_seimbang, target_seimbang)\nscores = k_best.scores_\n\n# Dapatkan nama fitur dari kolom data Anda\nfitur_names = fitur.columns\n\n# Tampilkan skor fitur berserta namanya\nfor i, (score, fitur_name) in enumerate(zip(scores, fitur_names)):\n    print(f\"Fitur {i}: {fitur_name}, Skor: {score}\")\n\nFitur 0: Gender, Skor: 0.0\nFitur 1: Age_at_diagnosis, Skor: 0.1844928943766866\nFitur 2: Race, Skor: 0.0\nFitur 3: IDH1, Skor: 0.3037068691204612\nFitur 4: TP53, Skor: 0.0114767531002542\nFitur 5: ATRX, Skor: 0.07239657961576484\nFitur 6: PTEN, Skor: 0.05205249513954713\nFitur 7: EGFR, Skor: 0.0\nFitur 8: CIC, Skor: 0.0634755402890419\nFitur 9: MUC16, Skor: 0.0\nFitur 10: PIK3CA, Skor: 0.021167499071111262\nFitur 11: NF1, Skor: 0.01522729428307068\nFitur 12: PIK3R1, Skor: 0.0\nFitur 13: FUBP1, Skor: 0.04306986744809804\nFitur 14: RB1, Skor: 0.034603512687797267\nFitur 15: NOTCH1, Skor: 0.05390188520546868\nFitur 16: BCOR, Skor: 0.004819449013254706\nFitur 17: CSMD3, Skor: 0.021559414485805117\nFitur 18: SMARCA4, Skor: 0.0\nFitur 19: GRIN2A, Skor: 0.0\nFitur 20: IDH2, Skor: 0.0\nFitur 21: FAT4, Skor: 0.005786907567380206\nFitur 22: PDGFRA, Skor: 0.0\n\n\n\nimport matplotlib.pyplot as plt\n\n# Tampilkan skor fitur dalam grafik\nplt.figure(figsize=(18, 6))\nplt.bar(fitur_names, scores)\nplt.xlabel(\"Nama Fitur\")\nplt.ylabel(\"Skor Fitur\")\nplt.title(\"Skor Fitur SelectKBest\")\nplt.xticks(rotation=90)\nplt.show()"
  },
  {
    "objectID": "main.html#modelling",
    "href": "main.html#modelling",
    "title": "1  TUGAS KLASIFIKASI DATA PROYEK SAINS DATA - B",
    "section": "1.4 MODELLING",
    "text": "1.4 MODELLING\n\n1.4.1 Load Dataset\n\nimport pandas as pd\n\ndata = pd.read_csv('dataset.csv')\ndata.head(5)\n\n\n\n\n\n\n\n\nGrade\nGender\nAge_at_diagnosis\nRace\nIDH1\nTP53\nATRX\nPTEN\nEGFR\nCIC\n...\nFUBP1\nRB1\nNOTCH1\nBCOR\nCSMD3\nSMARCA4\nGRIN2A\nIDH2\nFAT4\nPDGFRA\n\n\n\n\n0\n0\n0\n51.30\n0\n1\n0\n0\n0\n0\n0\n...\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n38.72\n0\n1\n0\n0\n0\n0\n1\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n2\n0\n0\n35.17\n0\n1\n1\n1\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3\n0\n1\n32.78\n0\n1\n1\n1\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n\n\n4\n0\n0\n31.51\n0\n1\n1\n1\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n5 rows × 24 columns\n\n\n\n\n#Banyak data dan kolom\n\nprint(\"Banyaknya data : \", data.shape[0])\nprint(\"Banyaknya kolom : \", data.shape[1])\n\nBanyaknya data :  839\nBanyaknya kolom :  24\n\n\n\n\n1.4.2 Split Dataset\n\nfrom sklearn.model_selection import train_test_split\n\n# melakukan pembagian dataset, dataset dibagi menjadi 80% data training dan 20% data testing\nfitur_train, fitur_test, target_train, target_test = train_test_split(fitur, target, test_size = 0.2, random_state=42)\n\n\n\n1.4.3 Grafik dan tingkat kepentingannya\n\nimport matplotlib.pyplot as plt\n\n# Tampilkan skor fitur dalam grafik\nplt.figure(figsize=(18, 6))\nplt.bar(fitur_names, scores)\n# Membuat label pada sumbu x dan y, serta judul pada grafiknya\nplt.xlabel(\"Nama Fitur\")\nplt.ylabel(\"Skor Fitur\")\nplt.title(\"Skor Fitur SelectKBest\")\n# Menambahkan rotasi pada sumbu x\nplt.xticks(rotation=90)\nplt.show()"
  },
  {
    "objectID": "main.html#data-preprocessing-1",
    "href": "main.html#data-preprocessing-1",
    "title": "1  TUGAS KLASIFIKASI DATA PROYEK SAINS DATA - B",
    "section": "1.5 Data Preprocessing",
    "text": "1.5 Data Preprocessing\nSetelah memahami data, akan dilakukan tahap preprocessing untuk menangani masalah pada data yang sudah didefinisikan pada data understanding, yakni. 1. Menghapus Data Duplikat 2. Menghapus Outlier 3. Menyeimbangkan proporsi data tiap target\nSetelah data siap, akan dilakukan : 1. Skoring tiap fitur kembali 2. Normalisasi Data 3. Eksplorasi Model\n\nimport pandas as pd\n\ndata = pd.read_csv('dataset.csv')\ndata.head(5)\n\n\n\n\n\n\n\n\nGrade\nGender\nAge_at_diagnosis\nRace\nIDH1\nTP53\nATRX\nPTEN\nEGFR\nCIC\n...\nFUBP1\nRB1\nNOTCH1\nBCOR\nCSMD3\nSMARCA4\nGRIN2A\nIDH2\nFAT4\nPDGFRA\n\n\n\n\n0\n0\n0\n51.30\n0\n1\n0\n0\n0\n0\n0\n...\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n38.72\n0\n1\n0\n0\n0\n0\n1\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n2\n0\n0\n35.17\n0\n1\n1\n1\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3\n0\n1\n32.78\n0\n1\n1\n1\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n\n\n4\n0\n0\n31.51\n0\n1\n1\n1\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n5 rows × 24 columns\n\n\n\n\n#Banyak data dan kolom\n\nprint(\"Banyaknya data : \", data.shape[0])\nprint(\"Banyaknya kolom : \", data.shape[1])\n\nBanyaknya data :  839\nBanyaknya kolom :  24\n\n\n\n1.5.1 Menghapus Data Duplikat\n\n# Menghapus data yang duplikat\ndata_bersih = data.drop_duplicates()\n\nprint(\"Banyaknya sisa data : \", data_bersih.shape[0])\n\n\n\n1.5.2 Menghapus Outlier\n\nfrom sklearn.neighbors import LocalOutlierFactor\n\n# Menggunakan Local Outlier Factor\nlof = LocalOutlierFactor(n_neighbors=5)\noutlier_scores = lof.fit_predict(data)\n\ndata_bersih = data[outlier_scores != -1]\nprint(\"Sisa data : \", data_bersih.shape[0])\n\n\n\n1.5.3 Menyeimbangkan Data Tiap Target\n\nfitur = data_bersih.drop(columns=['Grade'])\ntarget = data_bersih['Grade']\n\ntarget.value_counts()\n\n\n\n1.5.4 Menyeimbangkan data target sesuai jumlahnya menggunakan jumlah pada target yang paling sedikit\n\nfrom imblearn.under_sampling import RandomUnderSampler\n\nsmote = RandomUnderSampler()\nfitur_seimbang, target_seimbang = smote.fit_resample(fitur, target)\n\nprint(\"Jumlah sampel setelah diseimbangkan : \")\nprint(target_seimbang.value_counts())\n\n\n\n1.5.5 Simpan data yang telah seimbang di dalam database\n\nimport pandas as pd\n\n# Membuat DataFrame dari fitur dan target yang telah seimbang\ndata_seimbang = pd.concat([fitur_seimbang, target_seimbang], axis=1)\n\n# Menyimpan DataFrame ke dalam file CSV\ndata_seimbang.to_csv('Data_Seimbang.csv', index=False)\n\n\nfitur = data_seimbang.drop(columns=['Grade'])\ntarget = data_seimbang['Grade']\n\n\n\n1.5.6 Eksplorasi Data (Skoring Fitur)\nMelakukan skoring fitur dengan presentase kepentingannya\n\nfrom sklearn.feature_selection import SelectKBest, mutual_info_classif\n\n# Buat objek SelectKBest dengan mutual_info_classif sebagai fungsi skor\nk_best = SelectKBest(score_func=mutual_info_classif, k='all')  # 'all' berarti akan mempertahankan semua fitur\n\n# Hitung skor fitur\nk_best.fit(fitur, target)\nscores = k_best.scores_\n\n# Dapatkan nama fitur dari kolom data Anda\nfitur_names = fitur.columns\n\n# Tampilkan skor fitur berserta namanya\nfor i, (score, fitur_name) in enumerate(zip(scores, fitur_names)):\n    print(f\"Fitur {i}: {fitur_name}, Skor: {score}\")\n\nFitur 0: Gender, Skor: 0.0\nFitur 1: Age_at_diagnosis, Skor: 0.18672449077849174\nFitur 2: Race, Skor: 0.0010600399767952684\nFitur 3: IDH1, Skor: 0.2919775839551344\nFitur 4: TP53, Skor: 0.03145111467220385\nFitur 5: ATRX, Skor: 0.049446107986429455\nFitur 6: PTEN, Skor: 0.0814082771389042\nFitur 7: EGFR, Skor: 0.054840022727111526\nFitur 8: CIC, Skor: 0.07971535922808393\nFitur 9: MUC16, Skor: 0.0\nFitur 10: PIK3CA, Skor: 0.0\nFitur 11: NF1, Skor: 0.0\nFitur 12: PIK3R1, Skor: 0.0\nFitur 13: FUBP1, Skor: 0.009983749997428015\nFitur 14: RB1, Skor: 0.02414717554759105\nFitur 15: NOTCH1, Skor: 0.0\nFitur 16: BCOR, Skor: 0.003217834219356064\nFitur 17: CSMD3, Skor: 0.016862161428498057\nFitur 18: SMARCA4, Skor: 0.0\nFitur 19: GRIN2A, Skor: 0.0\nFitur 20: IDH2, Skor: 0.0\nFitur 21: FAT4, Skor: 0.0\nFitur 22: PDGFRA, Skor: 0.011853691523513898\n\n\n\nimport matplotlib.pyplot as plt\n\n# Tampilkan skor fitur dalam grafik\nplt.figure(figsize=(18, 6))\nplt.bar(fitur_names, scores)\n# Membuat label pada sumbu x dan y, serta judul pada grafiknya\nplt.xlabel(\"Nama Fitur\")\nplt.ylabel(\"Skor Fitur\")\nplt.title(\"Skor Fitur SelectKBest\")\n# Menambahkan rotasi pada sumbu x\nplt.xticks(rotation=90)\nplt.show()\n\n\n\n1.5.7 Split Data\n\nfrom sklearn.model_selection import train_test_split\n\n# melakukan pembagian dataset, dataset dibagi menjadi 80% data training dan 20% data testing\nfitur_train, fitur_test, target_train, target_test = train_test_split(fitur, target, test_size = 0.2, random_state=42)\n\n\nprint(\"Banyaknya fitur  : \", fitur_train.shape[1])\nprint(\"Banyaknya data latih : \", fitur_train.shape[0])\nprint(\"Banyaknya data testing : \", fitur_test.shape[0])\n\nBanyaknya fitur  :  23\nBanyaknya data latih :  648\nBanyaknya data testing :  162\n\n\n\ntarget_train.value_counts()\n\nGrade\n0    377\n1    271\nName: count, dtype: int64\n\n\n\nimport matplotlib.pyplot as plt\n\nvalue_counts = target_train.value_counts()\n\nplt.pie(value_counts, labels=value_counts.index, autopct='%.2f')\nplt.title('Perbandingan Jumlah Data Tiap Target')\nplt.axis('equal')\nplt.show()\n\n\n\n\n\n\n1.5.8 Normalisasi Data\n\n\n1.5.9 Menggunakan Standarscaler (zscore)\nRumus untuk mencari Zscore: \\[ Z = \\frac {X – μ}{σ} \\]\nPenjelasan rumusnya: - Z = nilai standar - X = nilai teramati - μ = mean sampel - σ = simpangan baku sampel\nRumus untuk standar deviasi sendiri sebagai berikut.\n\\[ s = \\sqrt{\\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})^2}{n - 1}} \\]\n\nimport pickle\nfrom sklearn.preprocessing import StandardScaler\n\n# menentukan lokasi file pickle akan disimpan\npath = 'zscore_scaler.pkl'\n\n# membuat dan melatih objek StandardScaler\nzscore_scaler = StandardScaler()\nzscore_scaler.fit(fitur_train)\n\n# menyimpan model ke dalam file pickle\nwith open(path, 'wb') as file:\n    pickle.dump(zscore_scaler, file)\n\n# memanggil kembali model normalisasi zscore dari file pickle\nwith open(path, 'rb') as file:\n    zscore_scaler = pickle.load(file)\n\n# menerapkan normalisasi zscore pada data training\nzscore_training = zscore_scaler.transform(fitur_train)\n\n# menerapkan normalisasi zscore pada data testing\nzscore_testing = zscore_scaler.transform(fitur_test)\n\n\nzscore_scaler\n\nStandardScaler()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.StandardScalerStandardScaler()\n\n\n\n\n1.5.10 Membuat model\n\n1.5.10.1 Konsep Naive Bayes\nNaïve Bayes Classifier merupakan sebuah metoda klasifikasi yang berakar pada teorema Bayes . Metode pengklasifikasian dengan menggunakan metode probabilitas dan statistik.\nRumus Naive Bayes:​ \\[ P(C|X) = \\frac {P(C) - P(X|C)}{P(X)} \\]\npenjelasan: - P(C|X) = nilai probabilitas posterior dari kelas C given fitur X - P(C) = Nilai probabilitas prior dari kelas C - P(X|C) = likelihood dari fitur X jika kelasnya adalah C - P(X) = nilai probabilitas evidensi atau probabilitas dari fitur X\n\\[ P(A) = \\frac {n(A)}{n(s)} \\]\nPenjelasan: - P(A) = peluang - n(A) = jumlah peluang yang mungkin terjadi - n(S) = jumlah sampel dari sebuah kejadian\n\n\n\n1.5.11 Menggunakan Minmaxscaler\nRumus untuk mencari Minmaxscaler:\n\\[ X' = \\frac{X - min}{max - min} \\]\nPenjelasan rumusnya: - X = nilai yang sudah di normalisasi - min = nilai data minimal - max = nilai data maksimal\nMenggunakan Metode Naive Bayes\n\nfrom sklearn.feature_selection import SelectKBest, mutual_info_classif\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score\n\nbest_accuracy_nb_zscore = 0\nbest_k_zscore = 0\nbest_accuracy_nb_minmax = 0\nbest_k_minmax = 0\n\nfor k in range(1, fitur_train.shape[1] + 1):\n    # Buat objek SelectKBest dengan mutual_info_classif sebagai fungsi skor\n    k_best = SelectKBest(score_func=mutual_info_classif, k=k)\n\n    # Fiturkan objek SelectKBest ke data training dan testing untuk kedua normalisasi (zscore dan minmax)\n    zscore_training_terbaik = k_best.fit_transform(zscore_training, target_train)\n    zscore_testing_terbaik = k_best.transform(zscore_testing)\n    minmaxtraining_terbaik = k_best.fit_transform(minmaxtraining, target_train)\n    minmaxtesting_terbaik = k_best.transform(minmaxtesting)\n\n    # Buat dan latih model dengan normalisasi zscore\n    model_zscore = GaussianNB()\n    model_zscore.fit(zscore_training_terbaik, target_train)\n\n    # Lakukan prediksi pada data uji dengan normalisasi zscore\n    y_pred_nb_zscore = model_zscore.predict(zscore_testing_terbaik)\n\n    # Hitung akurasi dengan normalisasi zscore\n    accuracy_nb_zscore = accuracy_score(target_test, y_pred_nb_zscore)\n\n    # Buat dan latih model dengan normalisasi minmax\n    model_minmax = GaussianNB()\n    model_minmax.fit(minmaxtraining_terbaik, target_train)\n\n    # Lakukan prediksi pada data uji dengan normalisasi minmax\n    y_pred_nb_minmax = model_minmax.predict(minmaxtesting_terbaik)\n\n    # Hitung akurasi dengan normalisasi minmax\n    accuracy_nb_minmax = accuracy_score(target_test, y_pred_nb_minmax)\n\n    # Memeriksa apakah akurasi dengan normalisasi zscore lebih baik dari yang sebelumnya\n    if accuracy_nb_zscore &gt; best_accuracy_nb_zscore:\n        best_accuracy_nb_zscore = accuracy_nb_zscore\n        best_k_zscore = k\n\n    # Memeriksa apakah akurasi dengan normalisasi minmax lebih baik dari yang sebelumnya\n    if accuracy_nb_minmax &gt; best_accuracy_nb_minmax:\n        best_accuracy_nb_minmax = accuracy_nb_minmax\n        best_k_minmax = k\n\nprint(\"Dengan Normalisasi Zscore:\")\nprint(\"Fitur terbaik yang bisa digunakan\", best_k_zscore, \"dengan akurasi : \", best_accuracy_nb_zscore)\n\nprint(\"Dengan Normalisasi Minmax:\")\nprint(\"Fitur terbaik yang bisa digunakan\", best_k_minmax, \"dengan akurasi : \", best_accuracy_nb_minmax)\n\n# Ambil indeks fitur terbaik dari SelectKBest\nbest_feature_indices_zscore = SelectKBest(score_func=mutual_info_classif, k=best_k_zscore).fit(zscore_training, target_train).get_support(indices=True)\nbest_feature_indices_minmax = SelectKBest(score_func=mutual_info_classif, k=best_k_minmax).fit(minmaxtraining, target_train).get_support(indices=True)\n\n# Dapatkan nama fitur terbaik dari indeksnya\nbest_features_zscore = [fitur.columns[i] for i in best_feature_indices_zscore]\nbest_features_minmax = [fitur.columns[i] for i in best_feature_indices_minmax]\n\n\nprint(\"Fitur terbaik yang digunakan (dengan normalisasi Zscore):\")\nprint(best_features_zscore)\n\nprint(\"Fitur terbaik yang digunakan (dengan normalisasi Minmax):\")\nprint(best_features_minmax)\n\nDengan Normalisasi Zscore:\nFitur terbaik yang bisa digunakan 5 dengan akurasi :  0.8395061728395061\nDengan Normalisasi Minmax:\nFitur terbaik yang bisa digunakan 6 dengan akurasi :  0.8333333333333334\nFitur terbaik yang digunakan (dengan normalisasi Zscore):\n['Age_at_diagnosis', 'IDH1', 'ATRX', 'PTEN', 'EGFR']\nFitur terbaik yang digunakan (dengan normalisasi Minmax):\n['Age_at_diagnosis', 'IDH1', 'ATRX', 'PTEN', 'CIC', 'NOTCH1']\n\n\n\nimport pandas as pd\n\n# kolom-kolom yang ingin Anda pertahankan\nkolom_pilihan = ['IDH1', 'Age_at_diagnosis', 'CIC', 'NOTCH1', 'Grade']\n\n# Buat dataset baru hanya dengan kolom yang dipilih\ndataset_baru = data[kolom_pilihan]\n\n# Simpan dataset baru dalam file CSV\ndataset_baru.to_csv('dataset_baru_nb.csv', index=False)  # Simpan ke file CSV tanpa menyertakan indeks\n\n\ndataset_baru.head(5)\n\n\n\n\n\n\n\n\nIDH1\nAge_at_diagnosis\nCIC\nNOTCH1\nGrade\n\n\n\n\n0\n1\n51.30\n0\n0\n0\n\n\n1\n1\n38.72\n1\n0\n0\n\n\n2\n1\n35.17\n0\n0\n0\n\n\n3\n1\n32.78\n0\n0\n0\n\n\n4\n1\n31.51\n0\n0\n0\n\n\n\n\n\n\n\n\n\n1.5.12 Split Dataset\n\nfrom sklearn.model_selection import train_test_split\n\n# memisahkan kolom fitur dan target\nfitur = dataset_baru.drop(columns=['Grade'], axis =1)\ntarget = dataset_baru['Grade']\n\n# melakukan pembagian dataset, dataset dibagi menjadi 80% data training dan 20% data testing\nfitur_train, fitur_test, target_train, target_test = train_test_split(fitur, target, test_size = 0.2, random_state=42)\n\n\n\n1.5.13 Normalisasi Data\n\nimport pickle\nfrom sklearn.preprocessing import StandardScaler\n\n# menentukan lokasi file pickle akan disimpan\npath = 'zcorescaler_baru.pkl'\n\n# membuat dan melatih objek Standarscaler\nzscorescaler = StandardScaler()\nzscorescaler.fit(fitur_train)\n\n# menyimpan model ke dalam file pickle\nwith open(path, 'wb') as file:\n    pickle.dump(zscorescaler, file)\n\n# memanggil kembali model normalisasi minmaxscaler dari file pickle\nwith open(path, 'rb') as file:\n    zscorescaler = pickle.load(file)\n\n# menerapkan normalisasi zscore pada data training\nzscoretraining = zscorescaler.transform(fitur_train)\n\n# menerapkan normalisasi zscore pada data testing\nzscoretesting = zscorescaler.transform(fitur_test)\n\n### Membuat Model\n\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import GridSearchCV\n\n# Definisi model Gaussian Naive Bayes\nnb = GaussianNB()\n\n# Definisi grid parameter yang akan diuji\nparam_grid = {\n    'priors': [None],  # Anda dapat menentukan probabilitas prior jika memiliki pengetahuan sebelumnya tentang distribusi kelas\n    'var_smoothing': [19, 20, 16, 30]  # Hyperparameter yang mengontrol sebagian varians terbesar yang akan ditambahkan untuk stabilitas perhitungan\n}\n\n\n# Inisialisasi GridSearchCV\ngrid_search = GridSearchCV(estimator=nb, param_grid=param_grid, cv=5, n_jobs=-1)\n\n# Latih model dengan data latih dan mencari parameter terbaik\ngrid_search.fit(zscoretraining, target_train)\n\n# Hasil parameter terbaik\nbest_params = grid_search.best_params_\nprint(\"Parameter terbaik:\", best_params)\n\n# Model dengan parameter terbaik\nbest_nb = grid_search.best_estimator_\n\n# Evaluasi model terbaik pada data uji\naccuracy = best_nb.score(zscoretesting, target_test)\nprint(\"Akurasi model terbaik:\", accuracy)\n\nParameter terbaik: {'priors': None, 'var_smoothing': 19}\nAkurasi model terbaik: 0.5297619047619048\n\n\n\n\n1.5.14 Simpan Model\n\nimport pickle\n\n# Model dengan parameter terbaik\nbest_nb = grid_search.best_estimator_\n\n# Simpan model Decision Tree terbaik ke dalam file pickle\nwith open('best_nb_model.pkl', 'wb') as file:\n    pickle.dump(best_nb, file)\n\n# Evaluasi model terbaik pada data uji\naccuracy = best_nb.score(zscoretesting, target_test)\nprint(\"Akurasi model terbaik:\", accuracy)\n\nAkurasi model terbaik: 0.5297619047619048"
  },
  {
    "objectID": "main.html#evaluation",
    "href": "main.html#evaluation",
    "title": "1  TUGAS KLASIFIKASI DATA PROYEK SAINS DATA - B",
    "section": "1.6 EVALUATION",
    "text": "1.6 EVALUATION\n\nEvalution ini terdapat model Naive Bayes Classifier dengan menggunakan zscore\nNilai akurasinya yaitu sebesar 0.52\n\n\nfrom sklearn.metrics import accuracy_score\n\nwith open('best_nb_model.pkl', 'rb') as file:\n    model_nb = pickle.load(file)\n\nmodel_nb.fit(zscoretraining, target_train)\ny_pred_nb = model_nb.predict(zscoretesting)\n\n# akurasi\nakurasi_nb = accuracy_score(target_test, y_pred_nb)\nprint('Akurasi Naive Bayes Classifier : ', akurasi_nb)\n\nAkurasi Naive Bayes Classifier :  0.5297619047619048"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever."
  }
]